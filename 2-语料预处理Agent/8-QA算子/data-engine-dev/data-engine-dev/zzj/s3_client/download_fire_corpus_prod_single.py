import boto3
from botocore.exceptions import NoCredentialsError, ClientError
import os
import concurrent.futures
from concurrent.futures import ProcessPoolExecutor
import tqdm
import pandas as pd
import logging
import file_utils

# é…ç½®æ—¥å¿—ï¼Œç”¨äºè®°å½•å¤±è´¥çš„æ–‡ä»¶
logging.basicConfig(filename='download_failures.log', level=logging.ERROR,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# æ”¯æŒçš„æ–‡ä»¶æ‰©å±•å
SUPPORTED_EXTENSIONS = ["pdf", "epub", "azw","azw3", "mobi"]

class S3Util:
    def __init__(self, endpoint, ak, sk):
        self.endpoint = endpoint
        self.ak = ak
        self.sk = sk
        self.s3_client = self._create_s3_client()

    def _create_s3_client(self):
        """Create an S3 client."""
        return boto3.client(
            's3',
            endpoint_url=self.endpoint,
            aws_access_key_id=self.ak,
            aws_secret_access_key=self.sk
        )

    def download_file(self, bucket_name, object_key, download_dir):
        """Download a single file from S3 directly into the specified download directory."""
        filename = os.path.basename(object_key)
        download_path = os.path.join(download_dir, filename)

        # Create download directory if it does not exist
        os.makedirs(download_dir, exist_ok=True)

        try:
            response = self.s3_client.head_object(Bucket=bucket_name, Key=object_key)
            file_size = response['ContentLength']

            with tqdm.tqdm(total=file_size, unit='B', unit_scale=True, desc=f"Downloading {filename}", leave=False) as pbar:
                with open(download_path, 'wb') as file:
                    def progress_callback(bytes_downloaded):
                        pbar.update(bytes_downloaded)

                    self.s3_client.download_fileobj(bucket_name, object_key, file, Callback=progress_callback)
            return True, object_key, None  # æˆåŠŸ
        except Exception as e:
            error_msg = f"Failed to download {object_key}: {e}"
            print(error_msg)
            logging.error(error_msg)
            return False, object_key, str(e)  # å¤±è´¥

def worker(args):
    bucket_name, cid, download_dir, s3_util_params = args
    endpoint, ak, sk = s3_util_params
    s3_util = S3Util(endpoint, ak, sk)
    results = []
    for ext in SUPPORTED_EXTENSIONS:
        object_key = f"{cid}.{ext}"
        success, key, error = s3_util.download_file(bucket_name, object_key, download_dir)
        if success:
            return success, key, None  # æˆåŠŸä¸€ä¸ªå°±è¿”å›
        else:
            results.append((key, error))
    # å¦‚æœæ‰€æœ‰æ ¼å¼éƒ½å¤±è´¥äº†ï¼Œè¿”å›æœ€åä¸€ä¸ªé”™è¯¯
    return False, cid, results

if __name__ == "__main__":
    debug=False
    # S3 é…ç½®ä¿¡æ¯
    ENDPOINT = "http://172.20.90.11:8009"
    AK = "123456"
    SK = "inspuR12345"
    BUCKET_NAME = "corpus-prod"
    DOWNLOAD_DIR = "/mnt/data/zzj/fire_s3/data/åº“å†…æ¶ˆé˜²/download"
    prod_failed_path = "/mnt/data/zzj/fire_s3/data/prod_failed.jsonl"
    prod_successed_path = "/mnt/data/zzj/fire_s3/data/prod_successed.jsonl"
    os.makedirs(DOWNLOAD_DIR, exist_ok=True)

    file_path = "/mnt/data/zzj/fire_s3/data/åº“å†…æ¶ˆé˜².xlsx"
    df = pd.read_excel(file_path, sheet_name="åº“å†…ä¹¦å•æ€»è¡¨")
    arry_cid = df["CID"].dropna().astype(str).tolist()
    arry_cid.sort()

    s3_util_params = (ENDPOINT, AK, SK)

    tasks = [(BUCKET_NAME, cid.strip(), DOWNLOAD_DIR, s3_util_params) for cid in arry_cid]

    print(f"å¼€å§‹ä¸‹è½½ {len(arry_cid)} ä¸ª CID å¯¹åº”çš„æ–‡ä»¶ï¼ˆå¤šè¿›ç¨‹ï¼‰...")

    # with ProcessPoolExecutor(max_workers=8) as executor:
    #     results = list(tqdm.tqdm(executor.map(worker, tasks), total=len(tasks), desc="Overall Progress"))
    if debug:
         # å•æ¬¡è°ƒç”¨è°ƒè¯•æ¨¡å¼ - é€ä¸ªæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ (å•è¿›ç¨‹/å•çº¿ç¨‹)
        print("ğŸ”§ è°ƒè¯•æ¨¡å¼ï¼šé€ä¸ªæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡ï¼ˆå•çº¿ç¨‹ï¼‰")
        results = []
        
        # ä½¿ç”¨ tqdm æ˜¾ç¤ºæ€»ä½“è¿›åº¦
        for i, task in enumerate(tqdm.tqdm(tasks, desc="Debug Processing")):
            try:
                # å¯é€‰ï¼šæ‰“å°å½“å‰æ­£åœ¨å¤„ç†çš„ä»»åŠ¡
                # print(f"\nğŸ” å¤„ç†ä»»åŠ¡ {i+1}/{len(tasks)}: CID={task[1]}")
                
                result = worker(task)
                results.append(result)
                
                # å¯é€‰ï¼šæ‰“å°æ¯ä¸ªä»»åŠ¡çš„ç»“æœ
                # if result[0]:  # æˆåŠŸ
                #     print(f"   âœ… æˆåŠŸ: {result[1]}")
                # else:  # å¤±è´¥
                #     print(f"   âŒ å¤±è´¥: {result[1]}, é”™è¯¯: {result[2]}")
                    
            except Exception as e:
                error_msg = f"Task {i+1} for CID {task[1]} failed with exception: {e}"
                print(error_msg)
                logging.error(error_msg)
                results.append((False, task[1] if len(task) > 1 else "unknown", str(e)))
        
        # è°ƒè¯•æ¨¡å¼ä¸‹ä¹Ÿç»Ÿè®¡ç»“æœ
        failed_downloads = [res for res in results if not res[0]]
        print(f"\nğŸ”§ è°ƒè¯•å®Œæˆã€‚æ€»ä»»åŠ¡æ•°: {len(tasks)}, æˆåŠŸ: {len(results)-len(failed_downloads)}, å¤±è´¥: {len(failed_downloads)}")
        
        # ä¿å­˜å¤±è´¥ç»“æœ (å¦‚æœåœ¨è°ƒè¯•æ¨¡å¼ä¸‹ä¹Ÿæƒ³çœ‹å¤±è´¥åˆ—è¡¨)
        if failed_downloads:
            print("\nâŒ è°ƒè¯•æ¨¡å¼ä¸‹çš„å¤±è´¥æ–‡ä»¶ï¼š")
            for _, cid, errors in failed_downloads:
                print(f"  - CID: {cid}, Errors: {errors}")
            # å¦‚æœ file_utils æ¨¡å—å¯ç”¨ä¸”ä½ æƒ³åœ¨è°ƒè¯•æ—¶ä¹Ÿä¿å­˜
            # file_utils.save_to_jsonl(failed_downloads, prod_failed_path)
    else:
        # åˆ›å»ºæ€»ä½“è¿›åº¦æ¡
        with tqdm.tqdm(total=len(tasks), desc="Total Files Progress", unit="files") as total_pbar:
            def update_progress(future):
                """æ›´æ–°æ€»ä½“è¿›åº¦æ¡çš„å›è°ƒå‡½æ•°"""
                total_pbar.update(1)

            with ProcessPoolExecutor(max_workers=128) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                futures = [executor.submit(worker, task) for task in tasks]
                
                # ä¸ºæ¯ä¸ªfutureæ·»åŠ å®Œæˆå›è°ƒ
                for future in futures:
                    future.add_done_callback(lambda f: total_pbar.update(1))
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                results = []
                for future in tqdm.tqdm(concurrent.futures.as_completed(futures), 
                                    total=len(futures), 
                                    desc="Processing Files", 
                                    leave=False):
                    try:
                        result = future.result()
                        results.append(result)
                    except Exception as e:
                        print(f"Task failed with exception: {e}")
                        results.append((False, "unknown", str(e)))

        failed_downloads = [res for res in results if not res[0]]
        success_downloads = [res for res in results if res[0]]
        file_utils.save_to_jsonl(success_downloads,prod_successed_path)
        print(f"\nâœ… ä¸‹è½½å®Œæˆã€‚æ€»å…±å¤±è´¥æ–‡ä»¶æ•°: {len(failed_downloads)}")
        if failed_downloads:
            print("\nâŒ ä»¥ä¸‹æ–‡ä»¶ä¸‹è½½å¤±è´¥ï¼š")
            for _, cid, errors in failed_downloads:
                print(f"  - CID: {cid}, Errors: {errors}")
            file_utils.save_to_jsonl(failed_downloads,prod_failed_path)
        