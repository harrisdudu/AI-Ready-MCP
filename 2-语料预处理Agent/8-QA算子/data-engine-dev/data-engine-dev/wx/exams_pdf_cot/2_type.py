#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ä» *.md æ–‡ä»¶çš„å‰50è¡Œ + å50è¡Œæ–‡æœ¬ç‰‡æ®µï¼Œåˆ¤æ–­å››ç±»è¯•é¢˜ç‰ˆå¼ï¼š
1) ONLY_QUESTIONS                -> åªæœ‰é¢˜
2) ONLY_ANSWERS_EXPLANATIONS     -> åªæœ‰ç­”æ¡ˆå’Œè§£æ
3) MIXED_TOGETHER                -> é¢˜å’Œç­”æ¡ˆè§£æåœ¨ä¸€èµ·
4) ANSWERS_AT_END                -> ç­”æ¡ˆå’Œè§£æåœ¨æœ€å

ç”¨æ³•ç¤ºä¾‹ï¼š
  python 2_type.py "/home/wangxi/workspace/gongye/ä¸€çº§é€ ä»·/mineru_ocred" \
    --recursive --pattern "*.md" --max-workers 8

ä¾èµ–ï¼š
  pip install tqdm rich pandas "volcengine-python-sdk[ark]"
"""

import os
import re
import json
import argparse
import concurrent.futures as cf
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict, Counter
from tqdm import tqdm
from rich import print
import pandas as pd
import time
from datetime import datetime


# ========== å†™æ­»çš„ Ark é…ç½® ==========
API_KEY   = "c702676e-a69f-4ff0-a672-718d0d4723ed"
MODEL_ID  = "doubao-seed-1-6-250615"
BACKEND   = "ark"  # å›ºå®š

# å‚æ•°é»˜è®¤å€¼
DEFAULT_TEMPERATURE = 0.0
DEFAULT_TOP_P       = 0.9
DEFAULT_TIMEOUT     = 60
DEFAULT_MAX_CHARS   = 6000

# Ark SDK
try:
    from volcenginesdkarkruntime import Ark
except Exception as e:
    raise SystemExit("âŒ éœ€è¦å®‰è£… Ark SDK: pip install 'volcengine-python-sdk[ark]'")

LABELS = {
    "ONLY_QUESTIONS": "åªæœ‰é¢˜",
    "ONLY_ANSWERS_EXPLANATIONS": "åªæœ‰ç­”æ¡ˆå’Œè§£æ",
    "MIXED_TOGETHER": "é¢˜å’Œç­”æ¡ˆè§£æåœ¨ä¸€èµ·",
    "ANSWERS_AT_END": "ç­”æ¡ˆå’Œè§£æåœ¨æœ€å",
}

SYSTEM_PROMPT = (
    "ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„è¯•å·ç‰ˆå¼åˆ†ç±»åŠ©æ‰‹ã€‚ä½ å°†çœ‹åˆ°æŸä¸ªMarkdownæ–‡ä»¶çš„ç‰‡æ®µï¼ˆæ¥è‡ªå‰50è¡Œå’Œå50è¡Œï¼‰ã€‚"
    "è¯·ä»…åŸºäºè¿™äº›ç‰‡æ®µåˆ¤æ–­æ•´ä»½è¯•å·çš„é¢˜ä¸ç­”æ¡ˆè§£æç»„ç»‡å½¢å¼ï¼Œå¹¶è¾“å‡ºJSONï¼š"
    '{"type":"<å››é€‰ä¸€æ ‡ç­¾>","confidence":0.0~1.0,"rationale":"ç®€è¿°ä¾æ®è¦ç‚¹"}'
    "å››ä¸ªåˆæ³•æ ‡ç­¾ï¼š"
    "ONLY_QUESTIONSï¼ˆåªæœ‰é¢˜ï¼‰ï¼Œ"
    "ONLY_ANSWERS_EXPLANATIONSï¼ˆåªæœ‰ç­”æ¡ˆæˆ–è§£æï¼‰ï¼Œ"
    "MIXED_TOGETHERï¼ˆé¢˜å’Œç­”æ¡ˆè§£æåœ¨ä¸€èµ·ï¼‰ï¼Œ"
    "ANSWERS_AT_ENDï¼ˆç­”æ¡ˆå’Œè§£æåœ¨æœ€åï¼‰ã€‚"
)

USER_PROMPT_TEMPLATE = """è¯·é˜…è¯»ä»¥ä¸‹ç‰‡æ®µï¼ˆæŒ‰åŸå§‹è¡Œé¡ºåºæ‹¼æ¥ï¼‰ï¼š

[å‰50è¡Œç‰‡æ®µ]
----------------
{front_excerpt}

[å50è¡Œç‰‡æ®µ]
----------------
{back_excerpt}

åˆ¤å®šæ ‡å‡†æç¤ºï¼š
- è‹¥åªæœ‰é¢˜å¹²ã€é¢˜å·ã€é€‰é¡¹ç­‰ï¼Œæ— ç­”æ¡ˆ/è§£æç­‰æè¿°ï¼Œå€¾å‘ ONLY_QUESTIONSã€‚
- è‹¥å‡ ä¹åªæœ‰ç­”æ¡ˆ/è§£æ/å‚è€ƒç­”æ¡ˆ/å‚è€ƒç­‰ç±»ä¼¼æè¿°ï¼Œæ— é¢˜å¹²ï¼Œå€¾å‘ ONLY_ANSWERS_EXPLANATIONSã€‚
- è‹¥åŒä¸€é¡µæˆ–ç´§é‚»å¤„æ—¢æœ‰æå¹²åˆæœ‰è§£æï¼Œå€¾å‘ MIXED_TOGETHERã€‚
- è‹¥å‰éƒ¨å¤šä¸ºé¢˜å¹²ï¼Œæœ«å°¾é›†ä¸­å‡ºç°ç­”æ¡ˆ/è§£æ/å‚è€ƒç­”æ¡ˆç­‰æè¿°ï¼Œå€¾å‘ ANSWERS_AT_ENDã€‚
- ç­”æ¡ˆæœ‰å¯èƒ½åœ¨è¡¨æ ¼é‡Œå‡ºç°ï¼Œéœ€è¦ç»“åˆè¡¨æ ¼å†…å®¹åˆ¤æ–­ã€‚
- æœ‰ä¸€äº›å‰é¢æœ‰ä¸€äº›å‰è¨€ä»‹ç»çš„ï¼Œå¯èƒ½ä¸æ˜¯é¢˜ï¼Œå®é™…è¿˜æ˜¯åªæœ‰ç­”æ¡ˆï¼Œè¦æ³¨æ„ã€‚

è¯·åªè¾“å‡ºä¸€ä¸ª JSONï¼Œä¸”å­—æ®µå®Œæ•´ï¼Œä¸è¦é¢å¤–æ–‡æœ¬ã€‚
"""

@dataclass
class ClassificationResult:
    file: str
    label: str
    label_cn: str
    confidence: float
    backend: str
    heuristic_used: bool
    elapsed_sec: float
    rationale: str
    front_preview: str
    back_preview: str
    raw_model_output: Optional[str] = None

# ---------------- Markdown è¯»ä¸æŠ½å– ----------------
def load_markdown(path: Path) -> List[str]:
    with open(path, "r", encoding="utf-8") as f:
        return f.readlines()

def pick_front_back_lines(lines: List[str], n_each: int = 50) -> Tuple[str, str]:
    if not lines:
        return "", ""
    
    # å‰n_eachè¡Œ
    front_lines = lines[:n_each]
    front = "".join(front_lines).strip()
    
    # ån_eachè¡Œ
    back_lines = lines[-n_each:] if len(lines) > n_each else []
    back = "".join(back_lines).strip()
    
    return front, back

# ---------------- æ¨¡å‹è°ƒç”¨ï¼ˆArkï¼‰ ----------------
def call_model_ark(model_id: str, system: str, user: str,
                   temperature: float, top_p: float, timeout: int) -> str:
    key = (API_KEY or "").strip()
    if not key:
        raise RuntimeError("ç¼ºå°‘ Ark API Keyã€‚")
    client = Ark(api_key=key)
    resp = client.chat.completions.create(
        model=model_id,
        messages=[{"role": "system", "content": system},
                  {"role": "user", "content": user}],
        temperature=temperature,
        top_p=top_p,
    )
    try:
        return resp.choices[0].message.content
    except Exception:
        return str(resp)

def parse_model_json(s: str) -> Optional[Dict[str, Any]]:
    if s is None:
        return None
    txt = s.strip()
    m = re.findall(r"```json(.*?)```", txt, flags=re.S | re.I)
    if m:
        txt = m[0].strip()
    m2 = re.search(r"\{.*\}", txt, flags=re.S)
    if m2:
        cand = m2.group(0)
        try:
            return json.loads(cand)
        except Exception:
            pass
    try:
        return json.loads(txt)
    except Exception:
        return None

# ---------------- å¯å‘å¼å…œåº• ----------------
def heuristic_guess(front: str, back: str) -> Tuple[str, float, str]:
    def score(tokens: List[str], text: str) -> int:
        s = 0
        for t in tokens:
            s += len(re.findall(re.escape(t), text, flags=re.I))
        return s

    q_tokens = ["é¢˜ç›®", "è¯•é¢˜", "å•é€‰", "å¤šé€‰", "åˆ¤æ–­", "æ¡ˆä¾‹", "é—®ç­”", "A.", "B.", "C.", "D.", "ã€é¢˜å¹²ã€‘"]
    a_tokens = ["ç­”æ¡ˆ", "å‚è€ƒç­”æ¡ˆ", "è§£æ", "è§£ç­”", "ã€ç­”æ¡ˆã€‘", "ã€è§£æã€‘", "è¯„åˆ†æ ‡å‡†", "æ­£ç¡®ç­”æ¡ˆ"]

    fq, fa = score(q_tokens, front), score(a_tokens, front)
    bq, ba = score(q_tokens, back), score(a_tokens, back)
    rationale = f"è®¡æ•°â†’ å‰:é¢˜={fq} ç­”/è§£={fa}; å:é¢˜={bq} ç­”/è§£={ba}"

    if (fq + bq) > 0 and (fa + ba) == 0:
        return "ONLY_QUESTIONS", 0.6, rationale
    if (fa + ba) > 0 and (fq + bq) == 0:
        return "ONLY_ANSWERS_EXPLANATIONS", 0.6, rationale
    if (fq > 0 and fa > 0) or (bq > 0 and ba > 0):
        return "MIXED_TOGETHER", 0.55, rationale
    if fq > 0 and (ba > fa + 1):
        return "ANSWERS_AT_END", 0.65, rationale

    return "MIXED_TOGETHER", 0.5, rationale + "ï¼ˆé»˜è®¤çŒœæµ‹ï¼‰"

# ---------------- ä¸»åˆ†ç±»é€»è¾‘ ----------------
def classify_one(md_path: Path,
                 temperature: float = DEFAULT_TEMPERATURE,
                 top_p: float = DEFAULT_TOP_P,
                 timeout: int = DEFAULT_TIMEOUT,
                 max_chars: int = DEFAULT_MAX_CHARS) -> ClassificationResult:
    t0 = time.time()
    try:
        lines = load_markdown(md_path)
    except Exception as e:
        raise RuntimeError(f"è¯»å– Markdown å¤±è´¥ï¼š{md_path} -> {e}")

    front, back = pick_front_back_lines(lines, 50)

    front_cut = (front or "")[:max_chars]
    back_cut  = (back or "")[:max_chars]

    user_prompt = USER_PROMPT_TEMPLATE.format(front_excerpt=front_cut, back_excerpt=back_cut)

    raw = None
    label, conf, rationale = None, 0.0, ""

    try:
        raw = call_model_ark(MODEL_ID, SYSTEM_PROMPT, user_prompt, temperature, top_p, timeout)
        obj = parse_model_json(raw)
        if isinstance(obj, dict) and "type" in obj:
            t = obj.get("type")
            c = float(obj.get("confidence", 0.0) or 0.0)
            r = str(obj.get("rationale", ""))[:2000]
            if t in LABELS:
                label, conf, rationale = t, max(0.0, min(1.0, c)), r
    except Exception as e:
        raw = f"[MODEL_ERROR] {e}"

    heuristic_used = False
    if label is None:
        heuristic_used = True
        label, conf, heur_r = heuristic_guess(front_cut, back_cut)
        rationale = (rationale + " | " if rationale else "") + f"[heuristic] {heur_r}"

    elapsed = time.time() - t0
    return ClassificationResult(
        file=str(md_path),
        label=label,
        label_cn=LABELS.get(label, label),
        confidence=conf,
        backend=BACKEND,
        heuristic_used=heuristic_used,
        elapsed_sec=elapsed,
        rationale=rationale,
        front_preview=front_cut[:1000],
        back_preview=back_cut[:1000],
        raw_model_output=(raw[:4000] if isinstance(raw, str) else None),
    )

# ---------------- æ‰«æä¸ä¸»å‡½æ•° ----------------
def iter_md_files(path: Path, recursive: bool, pattern: str) -> List[Path]:
    if path.is_file() and path.suffix.lower() == ".md":
        return [path]
    glob_pat = f"**/{pattern}" if recursive else pattern
    return sorted(path.glob(glob_pat))

def main():
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    ap = argparse.ArgumentParser(description="åŸºäº *.md æ–‡ä»¶çš„å‰50è¡Œ+å50è¡Œåˆ¤å®šè¯•å·ç±»å‹ï¼ˆå››ç±», Ark å›ºå®šï¼‰")
    ap.add_argument("path", help="å•ä¸ª Markdown æ–‡ä»¶æˆ–ç›®å½•")
    ap.add_argument("--recursive", action="store_true", help="é€’å½’æ‰«æç›®å½•")
    ap.add_argument("--pattern", default="*.md", help="æ–‡ä»¶ååŒ¹é…æ¨¡å¼ï¼ˆé»˜è®¤ *.mdï¼‰")
    ap.add_argument("--max-workers", type=int, default=256, help="å¹¶å‘çº¿ç¨‹æ•°")
    ap.add_argument("--out-csv", default=f"classification_results_{timestamp}.csv")
    ap.add_argument("--out-jsonl", default=f"classification_results_{timestamp}.jsonl")
    ap.add_argument("--temperature", type=float, default=DEFAULT_TEMPERATURE)
    ap.add_argument("--top-p", type=float, default=DEFAULT_TOP_P)
    ap.add_argument("--timeout", type=int, default=DEFAULT_TIMEOUT)
    ap.add_argument("--max-chars", type=int, default=DEFAULT_MAX_CHARS, help="å‰/åç‰‡æ®µæˆªæ–­é•¿åº¦")
    args = ap.parse_args()

    root = Path(args.path)
    files = iter_md_files(root, args.recursive, args.pattern)
    if not files:
        print(f"[red]æ²¡æœ‰åŒ¹é…åˆ° Markdown æ–‡ä»¶ï¼š{root} (pattern={args.pattern})[/red]")
        return

    results: List[ClassificationResult] = []
    with cf.ThreadPoolExecutor(max_workers=args.max_workers) as ex:
        futs = [
            ex.submit(
                classify_one,
                md_path=fp,
                temperature=args.temperature,
                top_p=args.top_p,
                timeout=args.timeout,
                max_chars=args.max_chars,
            )
            for fp in files
        ]
        for f in tqdm(cf.as_completed(futs), total=len(futs), desc="Classifying"):
            try:
                results.append(f.result())
            except Exception as e:
                print(f"[yellow]å¤„ç†å¤±è´¥ï¼š{e}[/yellow]")

    rows = [asdict(r) for r in results]
    if rows:
        # CSVï¼ˆæ ¸å¿ƒå­—æ®µï¼‰
        df = pd.DataFrame([{
            "file": r["file"],
            "label": r["label"],
            "label_cn": r["label_cn"],
            "confidence": r["confidence"],
            "backend": r["backend"],
            "heuristic_used": r["heuristic_used"],
            "elapsed_sec": r["elapsed_sec"],
        } for r in rows])
        df.to_csv(args.out_csv, index=False, encoding="utf-8-sig")

        # JSONLï¼ˆå…¨é‡ï¼‰
        with open(args.out_jsonl, "w", encoding="utf-8") as fw:
            for r in rows:
                fw.write(json.dumps(r, ensure_ascii=False) + "\n")

        print(f"[green]âœ… å®Œæˆï¼š{len(rows)} ä¸ªæ–‡ä»¶[/green]")
        print(f"CSV â†’ {args.out_csv}")
        print(f"JSONL â†’ {args.out_jsonl}")

        # ===== æ–°å¢ï¼šåˆ†ç±»ç»Ÿè®¡ =====
        label_counts = Counter(r["label"] for r in rows)
        total_files = len(rows)
        print("\n[cyan]ğŸ“Š åˆ†ç±»ç»Ÿè®¡ï¼š[/cyan]")
        # å›ºå®šé¡ºåºè¾“å‡ºï¼Œæ–¹ä¾¿å¯¹é½
        order = ["ONLY_QUESTIONS","ONLY_ANSWERS_EXPLANATIONS","MIXED_TOGETHER","ANSWERS_AT_END"]
        for lbl in order:
            cnt = label_counts.get(lbl, 0)
            print(f"  {lbl:<28} {LABELS.get(lbl, lbl):<20} {cnt} ä¸ª ({(cnt/total_files if total_files else 0):.1%})")

    else:
        print("[yellow]æ²¡æœ‰ç»“æœå¯å¯¼å‡º[/yellow]")

if __name__ == "__main__":
    main()


# python 2_type.py "/home/wangxi/workspace/gongye/yijizaojia/mineru_ocred" --recursive --pattern "*.md" --max-workers 8