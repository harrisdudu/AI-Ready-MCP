#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# 
# ä¾èµ–å®‰è£…: pip install tqdm
# æˆ–: pip install -r requirements.txt

import os
import sys
import shlex
import csv
import time
import argparse
import subprocess
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from itertools import cycle
from threading import Lock
from tqdm import tqdm

DEFAULT_BACKEND = "vlm-sglang-client"

def parse_args():
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    p = argparse.ArgumentParser(description="Batch run mineru on a folder of PDFs (port-pool round-robin)")
    p.add_argument("input_dir", help="è¾“å…¥ç›®å½•ï¼ˆé€’å½’æ‰«æï¼‰")
    p.add_argument("output_dir", help="è¾“å‡ºæ ¹ç›®å½•")
    p.add_argument("--pattern", default="*.pdf", help="æ–‡ä»¶åŒ¹é…è§„åˆ™ï¼ˆé»˜è®¤ *.pdfï¼‰")
    p.add_argument("--max-workers", type=int, default=4, help="å¹¶å‘æ•°ï¼ˆé»˜è®¤4ï¼‰")
    p.add_argument("--resume", action="store_true", help="æ–­ç‚¹ç»­è·‘ï¼šè‹¥ç›®æ ‡å·²å­˜åœ¨ä¸”éç©ºåˆ™è·³è¿‡")
    p.add_argument("--clean-incomplete", action="store_true", help="æ¸…ç†ä¸å®Œæ•´çš„è¾“å‡ºç›®å½•ï¼ˆåœ¨resumeæ¨¡å¼ä¸‹ï¼‰")
    p.add_argument("--retries", type=int, default=1, help="å¤±è´¥é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤1ï¼‰")
    p.add_argument("--timeout", type=int, default=1800, help="å•ä»»åŠ¡è¶…æ—¶ç§’æ•°ï¼ˆé»˜è®¤1800=30minï¼‰")
    p.add_argument("--log-file", default=f"mineru_ocred/mineru_batch_{timestamp}.log", help="æ‰¹å¤„ç†æ—¥å¿—æ–‡ä»¶")
    p.add_argument("--summary-csv", default=f"mineru_ocred/mineru_summary_{timestamp}.csv", help="ç»“æœæ±‡æ€»CSV")
    p.add_argument("--extra", default="", help="ç»™ mineru è¿½åŠ çš„åŸæ ·å‚æ•°å­—ç¬¦ä¸²ï¼Œå¦‚ï¼š\"--xx 1 --yy abc\"")
    p.add_argument("--url-host", default="172.16.0.28", help="mineru æœåŠ¡ä¸»æœº/IPï¼ˆé»˜è®¤ 172.16.0.28ï¼‰")
    p.add_argument("--ports", default="30000-30007",
                   help="ç«¯å£åˆ—è¡¨æˆ–åŒºé—´ï¼Œä¾‹ï¼š'30000-30007' æˆ– '30000,30002,30005'")
    return p.parse_args()

def which(cmd: str) -> str | None:
    for p in os.environ.get("PATH", "").split(os.pathsep):
        c = Path(p) / cmd
        if c.exists() and os.access(c, os.X_OK):
            return str(c)
    return None

def parse_ports(spec: str) -> list[int]:
    spec = spec.strip()
    if "-" in spec:
        a, b = spec.split("-", 1)
        start, end = int(a), int(b)
        if end < start:
            start, end = end, start
        return list(range(start, end + 1))
    # comma
    return [int(x) for x in spec.split(",") if x.strip()]

def is_done(out_dir: Path) -> bool:
    """æ£€æŸ¥mineruæ˜¯å¦å·²ç»æˆåŠŸå®Œæˆå¤„ç†"""
    if not out_dir.exists():
        return False
    
    # ç°åœ¨mineruç›´æ¥åœ¨å½“å‰ç›®å½•è¾“å‡ºï¼Œæ£€æŸ¥vlmç›®å½•
    vlm_dir = out_dir / "vlm"
    
    if not vlm_dir.exists() or not vlm_dir.is_dir():
        return False
    
    # æ£€æŸ¥vlmç›®å½•ä¸‹æ˜¯å¦æœ‰å…³é”®è¾“å‡ºæ–‡ä»¶
    # è‡³å°‘åº”è¯¥æœ‰.mdæ–‡ä»¶ï¼ˆmarkdownè¾“å‡ºï¼‰
    md_files = list(vlm_dir.glob("*.md"))
    if not md_files:
        return False
    
    # å¦‚æœè‡³å°‘æœ‰.mdæ–‡ä»¶ï¼Œä¸”æ–‡ä»¶å¤§å°ä¸ä¸º0ï¼Œåˆ™è®¤ä¸ºå¤„ç†å®Œæˆ
    for md_file in md_files:
        if md_file.stat().st_size > 0:
            return True
    
    return False

def run_once(pdf_path: Path, out_dir: Path, timeout: int, extra_args: str,
             log_f: Path, backend_url: str, args):
    out_dir.mkdir(parents=True, exist_ok=True)
    per_log = out_dir / "mineru_run.log"

    # ä¿®æ”¹mineruå‘½ä»¤ï¼Œä½¿ç”¨--no-subdirå‚æ•°é¿å…åˆ›å»ºå­ç›®å½•
    cmd = [
        "mineru",
        "-p", str(pdf_path),
        "-o", str(out_dir),
        "-b", DEFAULT_BACKEND,
        "-u", backend_url,
        "--no-subdir",  # ä¸åˆ›å»ºå­ç›®å½•ï¼Œç›´æ¥åœ¨å½“å‰ç›®å½•è¾“å‡º
    ]
    if extra_args.strip():
        cmd.extend(shlex.split(extra_args))

    start = time.time()
    with per_log.open("a", encoding="utf-8") as plog, log_f.open("a", encoding="utf-8") as blog:
        plog.write(f"[{datetime.now()}] URL={backend_url} CMD: {' '.join(shlex.quote(c) for c in cmd)}\n")
        blog.write(f"[{datetime.now()}] START {pdf_path} url={backend_url}\n")
        try:
            proc = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                timeout=timeout,
                check=False,
                text=True,
            )
            duration = time.time() - start
            plog.write(proc.stdout or "")
            plog.write(f"\n[duration_sec]={duration:.2f}, [returncode]={proc.returncode}\n")
            blog.write(f"[{datetime.now()}] END {pdf_path} code={proc.returncode} dur={duration:.2f}s url={backend_url}\n")
            return proc.returncode, duration, proc.stdout
        except subprocess.TimeoutExpired:
            duration = time.time() - start
            msg = f"[TIMEOUT] after {duration:.2f}s URL={backend_url}\n"
            with per_log.open("a", encoding="utf-8") as plog2:
                plog2.write(msg)
            with log_f.open("a", encoding="utf-8") as blog2:
                blog2.write(f"[{datetime.now()}] TIMEOUT {pdf_path} after {duration:.2f}s url={backend_url}\n")
            return 124, duration, msg
        except Exception as e:
            duration = time.time() - start
            err = f"[EXCEPTION] {type(e).__name__}: {e} URL={backend_url}\n"
            with per_log.open("a", encoding="utf-8") as plog2:
                plog2.write(err)
            with log_f.open("a", encoding="utf-8") as blog2:
                blog2.write(f"[{datetime.now()}] EXCEPTION {pdf_path}: {e} url={backend_url}\n")
            return 1, duration, err

class PortRoundRobin:
    def __init__(self, host: str, ports: list[int]):
        self._cycle = cycle([f"http://{host}:{p}" for p in ports])
        self._lock = Lock()
    def next(self) -> str:
        with self._lock:
            return next(self._cycle)

def make_worker(args, in_root: Path, out_root: Path, log_f: Path, rr: PortRoundRobin):
    def worker(pdf_path: Path):
        rel = pdf_path.relative_to(in_root)
        out_dir = (out_root / rel).with_suffix("")
        
        if args.resume:
            done = is_done(out_dir)
            if done:
                print(f"â­ï¸ è·³è¿‡å·²å®Œæˆçš„æ–‡ä»¶: {pdf_path.name}")
                return {
                    "pdf": str(pdf_path),
                    "out_dir": str(out_dir),
                    "status": "skipped_resume",
                    "returncode": 0,
                    "duration_sec": 0.0,
                    "tries": 0,
                    "url": ""
                }
            else:
                print(f"ğŸ”„ é‡æ–°å¤„ç†æ–‡ä»¶: {pdf_path.name}")
        
        last_rc = None
        total_dur = 0.0
        tries = 0
        for i in range(args.retries + 1):
            tries = i + 1
            backend_url = rr.next()             # è½®è¯¢ä¸€ä¸ª URL
            rc, dur, _ = run_once(pdf_path, out_dir, args.timeout, args.extra, log_f, backend_url, args)
            total_dur += dur
            last_rc = rc
            if rc == 0:
                break
            time.sleep(min(5, i * 2))           # ç®€å•é€€é¿
        status = "ok" if last_rc == 0 else "failed"
        return {
            "pdf": str(pdf_path),
            "out_dir": str(out_dir),
            "status": status,
            "returncode": last_rc,
            "duration_sec": round(total_dur, 2),
            "tries": tries,
            "url": backend_url if last_rc == 0 else ""
        }
    return worker

if __name__ == "__main__":
    args = parse_args()

    mineru_path = which("mineru")
    if not mineru_path:
        print("âŒ æœªæ‰¾åˆ° mineru å¯æ‰§è¡Œæ–‡ä»¶ï¼Œè¯·ç¡®è®¤å·²å®‰è£…å¹¶åœ¨ PATH ä¸­ã€‚", file=sys.stderr)
        sys.exit(2)

    in_root = Path(args.input_dir).resolve()
    out_root = Path(args.output_dir).resolve()
        
    out_root.mkdir(parents=True, exist_ok=True)
    log_f = Path(args.log_file).resolve()

    ports = parse_ports(args.ports)
    if not ports:
        print("âŒ ç«¯å£æ± ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ --ports å‚æ•°ã€‚", file=sys.stderr)
        sys.exit(2)

    print(f"â–¶ï¸ URL host: {args.url_host}, ports: {ports}")
    rr = PortRoundRobin(args.url_host, ports)

    pdfs = sorted(in_root.rglob(args.pattern))
    if not pdfs:
        print(f"âš ï¸ æœªæ‰¾åˆ°åŒ¹é…æ–‡ä»¶ï¼š{args.pattern} in {in_root}", file=sys.stderr)
        sys.exit(0)

    # å¦‚æœå¯ç”¨äº†æ¸…ç†ä¸å®Œæ•´ç›®å½•åŠŸèƒ½
    if args.resume and args.clean_incomplete:
        print("ğŸ§¹ æ¸…ç†ä¸å®Œæ•´çš„è¾“å‡ºç›®å½•...")
        cleaned_count = 0
        for pdf_path in pdfs:
            rel = pdf_path.relative_to(in_root)
            out_dir = (out_root / rel).with_suffix("")
            if out_dir.exists() and not is_done(out_dir):
                print(f"ğŸ—‘ï¸ åˆ é™¤ä¸å®Œæ•´ç›®å½•: {out_dir}")
                import shutil
                try:
                    shutil.rmtree(out_dir)
                    cleaned_count += 1
                except Exception as e:
                    print(f"âš ï¸ åˆ é™¤å¤±è´¥ {out_dir}: {e}")
        print(f"ğŸ§¹ æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleaned_count} ä¸ªä¸å®Œæ•´ç›®å½•")

    print(f"â–¶ï¸ å‘ç° {len(pdfs)} ä¸ªå¾…å¤„ç†æ–‡ä»¶ï¼Œå¹¶å‘æ‰§è¡Œï¼ˆworkers={args.max_workers}ï¼‰")

    worker = make_worker(args, in_root, out_root, log_f, rr)

    results = []
    with ThreadPoolExecutor(max_workers=args.max_workers) as ex:
        futures = [ex.submit(worker, pdf) for pdf in pdfs]
        
        # æ·»åŠ è¿›åº¦æ¡
        with tqdm(total=len(pdfs), desc="ğŸ“„ å¤„ç†PDFæ–‡ä»¶", unit="ä¸ª", 
                 bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]') as pbar:
            for fut in as_completed(futures):
                res = fut.result()
                results.append(res)
                mark = "âœ…" if res["status"] == "ok" else ("â­ï¸" if res["status"] == "skipped_resume" else "âŒ")
                print(f"{mark} {res['pdf']} -> {res['status']} (rc={res['returncode']}, tries={res['tries']}, {res['duration_sec']}s)")
                pbar.update(1)
                # æ›´æ–°è¿›åº¦æ¡æè¿°ä»¥æ˜¾ç¤ºå½“å‰çŠ¶æ€ç»Ÿè®¡
                ok_count = sum(1 for r in results if r["status"] == "ok")
                failed_count = sum(1 for r in results if r["status"] == "failed")
                skipped_count = sum(1 for r in results if r["status"] == "skipped_resume")
                pbar.set_postfix({
                    'âœ…': ok_count,
                    'âŒ': failed_count,
                    'â­ï¸': skipped_count
                })

    csv_path = Path(args.summary_csv).resolve()
    with csv_path.open("w", newline="", encoding="utf-8") as fw:
        writer = csv.DictWriter(fw, fieldnames=["pdf", "out_dir", "status", "returncode", "tries", "duration_sec", "url"])
        writer.writeheader()
        for r in results:
            writer.writerow(r)

    total = len(results)
    ok = sum(1 for r in results if r["status"] == "ok")
    skip = sum(1 for r in results if r["status"] == "skipped_resume")
    fail = sum(1 for r in results if r["status"] == "failed")
    print(f"\nğŸ“Š æ€»ç»“ï¼štotal={total}, ok={ok}, skipped={skip}, failed={fail}")
    print(f"ğŸ§¾ æ±‡æ€»è¡¨ï¼š{csv_path}")
    print(f"ğŸ—’ï¸ æ—¥å¿—ï¼š{log_f}")


# python 1_ocr_mineru.py /home/wangxi/workspace/gongye/ä¸€çº§é€ ä»· /home/wangxi/workspace/gongye/ä¸€çº§é€ ä»·/mineru_ocred --pattern "*.pdf" --max-workers 8 --resume --clean-incomplete --retries 2 --timeout 1800 --url-host 172.16.0.28 --ports 30000-30007