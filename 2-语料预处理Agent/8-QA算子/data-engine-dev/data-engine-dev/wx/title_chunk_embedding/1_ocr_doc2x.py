import os
import zipfile
import time
import shutil
from tqdm import tqdm
from datetime import datetime
from pypdf import PdfReader, PdfWriter
from pdfdeal import Doc2X

# === é…ç½® ===
API_KEY = "sk-q0skdac8mabmobtkrlsuxdjrv4kkb9uf"
INPUT_DIR = "/home/wangxi/workspace/xiaofang/original"
OUTPUT_DIR = "/home/wangxi/workspace/xiaofang/doc2x_ocred"
MAX_RETRIES = 5
RETRY_DELAY = 10
MAX_FILE_SIZE_MB = 300  # è¶…è¿‡è¯¥å¤§å°ä¹Ÿè¦æ‹†åˆ†
TO_CONSOLE = True

# === åˆå§‹åŒ–æ—¥å¿— ===
LOG_FILE = os.path.join(OUTPUT_DIR, "doc2x_log.txt")
os.makedirs(OUTPUT_DIR, exist_ok=True)
with open(LOG_FILE, "a", encoding="utf-8") as f:
    f.write(f"\n\n========== è¿è¡Œå¼€å§‹ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ==========\n")

def log(msg):
    timestamp = datetime.now().strftime("[%Y-%m-%d %H:%M:%S]")
    full_msg = f"{timestamp} {msg}"
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(full_msg + "\n")
    if TO_CONSOLE:
        print(full_msg)

# === åˆå§‹åŒ– Doc2X å®¢æˆ·ç«¯ ===
try:
    client = Doc2X(apikey=API_KEY, debug=True)
except Exception as e:
    log(f"âŒ åˆå§‹åŒ– Doc2X å®¢æˆ·ç«¯å¤±è´¥ï¼š{e}")
    exit(1)

# === å·¥å…·å‡½æ•° ===
def get_pdf_page_count(pdf_path):
    try:
        reader = PdfReader(pdf_path)
        return len(reader.pages)
    except Exception as e:
        log(f"âŒ è·å–é¡µæ•°å¤±è´¥: {pdf_path} - {e}")
        return -1

def get_file_size_mb(file_path):
    try:
        return os.path.getsize(file_path) / (1024 * 1024)
    except Exception as e:
        log(f"âŒ è·å–æ–‡ä»¶å¤§å°å¤±è´¥: {file_path} - {e}")
        return -1

def split_pdf(pdf_path, output_dir):
    reader = PdfReader(pdf_path)
    total_pages = len(reader.pages)
    file_size_mb = get_file_size_mb(pdf_path)
    stem = os.path.splitext(os.path.basename(pdf_path))[0]
    split_paths = []

    # è®¡ç®—æ‹†åˆ†ä»½æ•°ï¼ˆé¡µæ•°ä¼˜å…ˆï¼‰
    if total_pages > 1000:
        num_parts = (total_pages + 999) // 1000
    elif file_size_mb > MAX_FILE_SIZE_MB:
        # å¦‚æœä»…æ˜¯å¤§å°è¶…è¿‡é™åˆ¶ï¼ŒæŒ‰å¹³å‡å¤§å°æ‹†åˆ†
        # å‡è®¾æ¯é¡µå¤§å°è¿‘ä¼¼ï¼ŒæŒ‰é¡µæ•°å¹³å‡æ‹†
        estimated_pages_per_part = max(1, int(total_pages * (MAX_FILE_SIZE_MB / file_size_mb)))
        num_parts = (total_pages + estimated_pages_per_part - 1) // estimated_pages_per_part
    else:
        num_parts = 1  # ä¸æ‹†åˆ†

    pages_per_part = (total_pages + num_parts - 1) // num_parts

    for i in range(num_parts):
        writer = PdfWriter()
        start_page = i * pages_per_part
        end_page = min(start_page + pages_per_part, total_pages)

        for j in range(start_page, end_page):
            writer.add_page(reader.pages[j])

        split_name = f"{stem}_part{i+1}.pdf"
        split_path = os.path.join(output_dir, split_name)
        with open(split_path, "wb") as f:
            writer.write(f)
        split_paths.append(split_path)
        log(f"ğŸ“„ æ‹†åˆ†ç”Ÿæˆ: {split_path}ï¼ˆé¡µç  {start_page+1}-{end_page}ï¼‰")

    return split_paths

def merge_md_parts(md_dir, stem):
    part_md_files = sorted([
        os.path.join(md_dir, f) for f in os.listdir(md_dir)
        if f.startswith(f"{stem}_part") and f.endswith(".md")
    ])
    output_md_path = os.path.join(md_dir, f"{stem}.md")
    
    # æ£€æŸ¥æ˜¯å¦å·²ç»åˆå¹¶è¿‡
    if os.path.exists(output_md_path) and os.path.getsize(output_md_path) > 0:
        log(f"â© å·²å­˜åœ¨åˆå¹¶åçš„ Markdownï¼Œè·³è¿‡åˆå¹¶: {output_md_path}")
        return
    
    if not part_md_files:
        log(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°éœ€è¦åˆå¹¶çš„æ‹†åˆ†æ–‡ä»¶: {stem}")
        return
    
    with open(output_md_path, "w", encoding="utf-8") as out_f:
        for md_file in part_md_files:
            with open(md_file, "r", encoding="utf-8") as in_f:
                out_f.write(in_f.read())
                out_f.write("\n\n")
    log(f"ğŸ“˜ åˆå¹¶ Markdown å®Œæˆ: {output_md_path}")

    # ğŸ”¥ åˆ é™¤åˆå¹¶å‰çš„ part md æ–‡ä»¶
    for part_md in part_md_files:
        try:
            os.remove(part_md)
            log(f"ğŸ—‘ï¸ åˆ é™¤æ‹†åˆ† Markdown: {part_md}")
        except Exception as e:
            log(f"âš ï¸ åˆ é™¤å¤±è´¥: {part_md} - {e}")

def process_pdf_with_retry(pdf_file_path, output_dir, retry_count=0):
    stem = os.path.splitext(os.path.basename(pdf_file_path))[0]
    expected_zip_path = os.path.join(output_dir, stem + ".zip")

    try:
        client.pdf2file(pdf_file=pdf_file_path, output_path=output_dir, output_format="md_dollar")
        if not os.path.exists(expected_zip_path):
            raise Exception("æœªæ‰¾åˆ° ZIP è¾“å‡ºæ–‡ä»¶")
        log(f"âœ… è½¬æ¢æˆåŠŸ: {pdf_file_path}")
        return True
    except Exception as e:
        if retry_count < MAX_RETRIES:
            log(f"âš ï¸ ç¬¬ {retry_count+1} æ¬¡é‡è¯•: {pdf_file_path} - é”™è¯¯: {str(e)}")
            time.sleep(RETRY_DELAY)
            return process_pdf_with_retry(pdf_file_path, output_dir, retry_count + 1)
        else:
            log(f"âŒ è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {pdf_file_path} - é”™è¯¯: {str(e)}")
            return False

def handle_zip_and_md(output_dir, stem):
    zip_path = os.path.join(output_dir, stem + ".zip")
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(output_dir)
        output_md = os.path.join(output_dir, "output.md")
        final_md = os.path.join(output_dir, stem + ".md")
        if os.path.exists(output_md):
            os.rename(output_md, final_md)
            log(f"âœ… Markdown é‡å‘½å: {output_md} â†’ {final_md}")
        else:
            log(f"âš ï¸ è§£å‹åæœªæ‰¾åˆ° output.md")
        os.remove(zip_path)
        log(f"ğŸ—‘ï¸ åˆ é™¤ ZIP: {zip_path}")
    except Exception as e:
        log(f"âŒ ZIP è§£å‹å¤±è´¥: {zip_path} - {e}")

def process_single_pdf(pdf_path, output_root_dir):
    stem = os.path.splitext(os.path.basename(pdf_path))[0]
    pdf_output_dir = os.path.join(output_root_dir, stem)
    final_md_path = os.path.join(pdf_output_dir, f"{stem}.md")

    # === æ–­ç‚¹ç»­ä¼ åˆ¤æ–­ ===
    if os.path.exists(final_md_path) and os.path.getsize(final_md_path) > 0:
        log(f"â© å·²å­˜åœ¨å®Œæ•´ Markdownï¼Œè·³è¿‡: {pdf_path}")
        return
    elif os.path.exists(pdf_output_dir):
        # å¦‚æœæ–‡ä»¶å¤¹å­˜åœ¨ä½†æ²¡æœ‰å®Œæ•´çš„mdæ–‡ä»¶ï¼Œæ¸…ç†æ®‹ç•™æ–‡ä»¶
        log(f"ğŸ§¹ æ¸…ç†æ®‹ç•™æ–‡ä»¶: {pdf_output_dir}")
        try:
            shutil.rmtree(pdf_output_dir)
        except Exception as e:
            log(f"âš ï¸ æ¸…ç†å¤±è´¥: {pdf_output_dir} - {e}")

    os.makedirs(pdf_output_dir, exist_ok=True)

    page_count = get_pdf_page_count(pdf_path)
    file_size_mb = get_file_size_mb(pdf_path)
    if page_count == -1 or file_size_mb == -1:
        log(f"âŒ è·³è¿‡ï¼ˆè·å–ä¿¡æ¯å¤±è´¥ï¼‰: {pdf_path}")
        return

    need_split = page_count > 1000 or file_size_mb >= MAX_FILE_SIZE_MB

    if not need_split:
        if process_pdf_with_retry(pdf_path, pdf_output_dir):
            handle_zip_and_md(pdf_output_dir, stem)
    else:
        log(f"âš ï¸ PDF éœ€æ‹†åˆ†: {pdf_path} ï¼ˆ{page_count} é¡µï¼Œ{file_size_mb:.2f} MBï¼‰")
        
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ‹†åˆ†éƒ¨åˆ†éƒ½å·²å¤„ç†å®Œæˆ
        all_parts_completed = True
        split_paths = split_pdf(pdf_path, pdf_output_dir)
        
        for part_path in split_paths:
            part_stem = os.path.splitext(os.path.basename(part_path))[0]
            part_md_path = os.path.join(pdf_output_dir, f"{part_stem}.md")
            
            if not os.path.exists(part_md_path) or os.path.getsize(part_md_path) == 0:
                all_parts_completed = False
                if process_pdf_with_retry(part_path, pdf_output_dir):
                    handle_zip_and_md(pdf_output_dir, part_stem)
            else:
                log(f"â© æ‹†åˆ†éƒ¨åˆ†å·²å­˜åœ¨: {part_md_path}")
        
        # åªæœ‰å½“æ‰€æœ‰éƒ¨åˆ†éƒ½å®Œæˆæ—¶æ‰åˆå¹¶
        if all_parts_completed or os.path.exists(final_md_path):
            merge_md_parts(pdf_output_dir, stem)
            for p in split_paths:
                os.remove(p)
            log(f"ğŸ§¹ æ‹†åˆ† PDF æ¸…ç†å®Œæˆ")

def run_processing():
    log(f"ğŸ“‚ æ‰«æç›®å½•: {INPUT_DIR}")
    for root, _, files in os.walk(INPUT_DIR):
        rel_path = os.path.relpath(root, INPUT_DIR)
        current_output_dir = os.path.join(OUTPUT_DIR, rel_path)
        os.makedirs(current_output_dir, exist_ok=True)

        for file in tqdm(files, desc=f"ğŸ“ {rel_path}", unit="file"):
            source_path = os.path.join(root, file)
            if file.lower().endswith(".pdf"):
                process_single_pdf(source_path, current_output_dir)
            else:
                dst_path = os.path.join(current_output_dir, file)
                try:
                    shutil.copy2(source_path, dst_path)
                    log(f"âœ… å¤åˆ¶éPDFæ–‡ä»¶: {source_path}")
                except Exception as e:
                    log(f"âŒ å¤åˆ¶å¤±è´¥: {source_path} - {e}")

    log("ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ")

if __name__ == "__main__":
    if not os.path.isdir(INPUT_DIR):
        log(f"âŒ è¾“å…¥ç›®å½•æ— æ•ˆ: {INPUT_DIR}")
    else:
        run_processing()