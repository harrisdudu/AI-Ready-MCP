#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥è®°å½•æŸ¥è¯¢ä¸å¯¼å‡ºä¸ºJSONè„šæœ¬

åŠŸèƒ½ï¼š
1. è¿æ¥æ•°æ®åº“ï¼Œè¯»å– CUSTUME.JCBGD è¡¨çš„æ£€æŸ¥è®°å½•æ•°æ®
2. å°†æ¯æ¡è®°å½•å¯¼å‡ºä¸ºå•ç‹¬çš„JSONæ–‡ä»¶
3. æ”¯æŒè‡ªå®šä¹‰è¾“å‡ºç›®å½•

ä½œè€…ï¼šAI Assistant
æ—¥æœŸï¼š2024
"""

import os
import sys
import json
import logging
# æ³¨æ„ï¼šæœ¬è„šæœ¬éœ€è¦cx_Oracleåº“è¿æ¥Oracleæ•°æ®åº“
# å¦‚æœªå®‰è£…ï¼Œè¯·ä½¿ç”¨å‘½ä»¤ï¼špip install cx_Oracle
from datetime import datetime
from typing import Dict, List, Optional
import argparse

# === é…ç½®æ—¥å¿—ç³»ç»Ÿ ===
def setup_logging(log_file='export_to_json.log'):
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

logger = setup_logging()

# === Oracleæ•°æ®åº“é…ç½® ===
DB_CONFIG = {
    'host': '172.28.10.1',  # OracleæœåŠ¡å™¨ä¸»æœºåæˆ–IP
    'port': '1521',          # Oracleç›‘å¬ç«¯å£ï¼Œé»˜è®¤ä¸º1521
    'sid': 'orcl',          # Oracle SIDæˆ–æœåŠ¡å
    'username': 'custume',  # Oracleç”¨æˆ·å
    'password': 'Kps@123456!'  # Oracleå¯†ç 
}

def get_db_connection():
    """è·å–Oracleæ•°æ®åº“è¿æ¥"""
    try:
        # å°è¯•å¯¼å…¥cx_Oracleåº“
        try:
            import cx_Oracle
        except ImportError:
            logger.error("âŒ æœªæ‰¾åˆ°cx_Oracleåº“ï¼Œè¯·å®‰è£…: pip install cx_Oracle")
            return None
        
        # æ„å»ºOracleè¿æ¥å­—ç¬¦ä¸²
        dsn = cx_Oracle.makedsn(
            DB_CONFIG['host'], 
            DB_CONFIG['port'], 
            sid=DB_CONFIG['sid']
        )
        
        # è¿æ¥æ•°æ®åº“
        conn = cx_Oracle.connect(
            user=DB_CONFIG['username'],
            password=DB_CONFIG['password'],
            dsn=dsn
        )
        
        logger.info(f"âœ… æˆåŠŸè¿æ¥Oracleæ•°æ®åº“: {DB_CONFIG['sid']}")
        return conn
    except Exception as e:
        logger.error(f"âŒ è¿æ¥Oracleæ•°æ®åº“å¤±è´¥: {e}")
        return None




class DataExporter:
    """æ•°æ®å¯¼å‡ºå™¨"""
    
    def __init__(self, output_dir: str = 'json_exports'):
        self.output_dir = output_dir
        self.ensure_output_dir()
        self.dump_count = 0
        self.package_size = 300
    
    def ensure_output_dir(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        os.makedirs(self.output_dir, exist_ok=True)
        logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def datetime_to_str(self, obj):
        """å°†æ—¥æœŸæ—¶é—´å¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå…¼å®¹Oracleæ•°æ®åº“ç±»å‹"""
        # å¤„ç†datetimeå¯¹è±¡
        if isinstance(obj, datetime):
            return obj.isoformat()
        # å¤„ç†cx_Oracleçš„DATEå’ŒTIMESTAMPç±»å‹
        try:
            # å°è¯•å°†å¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆé€‚ç”¨äºcx_Oracleçš„æ—¥æœŸç±»å‹ï¼‰
            if hasattr(obj, 'isoformat'):
                return obj.isoformat()
            elif hasattr(obj, 'strftime'):
                return obj.strftime('%Y-%m-%dT%H:%M:%S')
        except:
            pass
        # å¦‚æœä»¥ä¸Šéƒ½ä¸é€‚ç”¨ï¼Œè¿”å›åŸå§‹å€¼
        return obj
    
    def clean_filename(self, filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
        # ç§»é™¤æˆ–æ›¿æ¢æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
        invalid_chars = '<>:"/\\|?*'
        for char in invalid_chars:
            filename = filename.replace(char, '_')
        return filename
    
    def get_all_records(self) -> List[Dict]:
        """ä»æ•°æ®åº“è·å–æ‰€æœ‰æ£€æŸ¥è®°å½•"""
        try:
            conn = get_db_connection()
            if not conn:
                logger.error("âŒ æ— æ³•è¿æ¥æ•°æ®åº“")
                return []
            
            try:
                cursor = conn.cursor()
                
                # ä½¿ç”¨å›¾ç‰‡æŸ¥è¯¢SQL
                query = """
                SELECT 
                    ä½é™¢å· AS æµæ°´å·,
                    æŠ¥å‘Šæ—¥æœŸ AS å®¡æ ¸æ—¶é—´,
                    æ£€æŸ¥å· AS æ£€æŸ¥å•å·,
                    åˆ†ç±»,
                    æŠ¥å‘Šåç§° AS æ£€æŸ¥åç§°,
                    è¯Šæ–­æè¿° AS æ£€æŸ¥æ‰€è§,
                    ç»“æœä¸æè¿° AS æ£€æŸ¥ç»“æœ,
                    æ£€æŸ¥éƒ¨ä½
                FROM 
                    CUSTUME.JCBGD
                WHERE 
                    (åˆ†ç±» = 'NJ' 
                     OR åˆ†ç±» = 'XHBL'
                     OR åˆ†ç±» = 'BL' AND (è¯Šæ–­æè¿° LIKE '%è‚ %' OR è¯Šæ–­æè¿° LIKE '%èƒƒ%'))
                    AND ä½é™¢å· IN (
                        SELECT ä½é™¢å·
                        FROM CUSTUME.ä¸­é—´ä¸´æ—¶è¡¨2)
                """
                
                cursor.execute(query)
                columns = [column[0] for column in cursor.description]
                
                records = []
                for row in cursor.fetchall():
                    record = dict(zip(columns, row))
                    # è½¬æ¢datetimeå¯¹è±¡ä¸ºå­—ç¬¦ä¸²
                    for key, value in record.items():
                        record[key] = self.datetime_to_str(value)
                    records.append(record)
                
                cursor.close()
                logger.info(f"âœ… æˆåŠŸè·å– {len(records)} æ¡æ£€æŸ¥è®°å½•")
                return records
                
            finally:
                conn.close()
                logger.info("ğŸ”Œ æ•°æ®åº“è¿æ¥å·²å…³é—­")
                
        except Exception as e:
            logger.error(f"âŒ è·å–æ£€æŸ¥è®°å½•å¤±è´¥: {e}")
            return []
    


    def export_single_records(self, records: List[Dict]):
        """å¯¼å‡ºè®°å½•ä¸ºå•ç‹¬çš„JSONæ–‡ä»¶"""
        logger.info("ğŸ“¤ å¼€å§‹å¯¼å‡ºè®°å½•ä¸ºå•ç‹¬çš„JSONæ–‡ä»¶")
        
        exported_count = 0
        for i, record in enumerate(records, 1):
            try:
                # ç”Ÿæˆæ–‡ä»¶å
                record_id = f"record_{i}"
                filename = f"{record_id}.json"

                # æ„å»ºè¾“å‡ºæ•°æ®ç»“æ„
                out_data = {
                    'æµæ°´å·': record.get('æµæ°´å·', ''),
                    'å®¡æ ¸æ—¶é—´': record.get('å®¡æ ¸æ—¶é—´', ''),
                    'æ£€æŸ¥å•å·': record.get('æ£€æŸ¥å•å·', ''),
                    'åˆ†ç±»': record.get('åˆ†ç±»', ''),
                    'æ£€æŸ¥åç§°': record.get('æ£€æŸ¥åç§°', ''),
                    'æ£€æŸ¥æ‰€è§': record.get('æ£€æŸ¥æ‰€è§', ''),
                    'æ£€æŸ¥ç»“æœ': record.get('æ£€æŸ¥ç»“æœ', ''),
                    'æ£€æŸ¥éƒ¨ä½': record.get('æ£€æŸ¥éƒ¨ä½', ''),
                }

                out = {'data': out_data}
                self.dump_count += 1
                package_number = self.dump_count // self.package_size
                if self.dump_count % self.package_size:
                    package_number += 1

                file_path = os.path.join(self.output_dir, str(package_number), filename)
                os.makedirs(os.path.dirname(file_path), exist_ok=True)
                # å†™å…¥JSONæ–‡ä»¶
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(out, f, ensure_ascii=False, indent=4)
                
                exported_count += 1
                if exported_count % 100 == 0:
                    logger.info(f"ğŸ“„ å·²å¯¼å‡º {exported_count} æ¡è®°å½•...")
                    
            except Exception as e:
                logger.error(f"âŒ å¯¼å‡ºè®°å½• {i} å¤±è´¥: {e}")
                continue
        
        logger.info(f"âœ… è®°å½•å¯¼å‡ºå®Œæˆï¼Œå…±å¯¼å‡º {exported_count} ä¸ªæ–‡ä»¶")
    
    def run(self, export_mode: str = 'single'):
        """è¿è¡Œæ•°æ®å¯¼å‡ºæµç¨‹"""
        logger.info("ğŸš€ å¼€å§‹æ•°æ®å¯¼å‡ºæµç¨‹")
        
        # è·å–æ•°æ®
        records = self.get_all_records()
        if not records:
            logger.error("âŒ æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
            return
        
        # å¯¼å‡ºè®°å½•
        self.export_single_records(records)
        
        logger.info("ğŸ‰ æ•°æ®å¯¼å‡ºå®Œæˆï¼")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å›¾ç‰‡æ•°æ®æŸ¥è¯¢ä¸å¯¼å‡ºä¸ºJSONå·¥å…·")
    parser.add_argument("--output-dir", default="json_exports", help="è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: json_exportsï¼‰")
    parser.add_argument("--log-file", default="export_to_json.log", help="æ—¥å¿—æ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    global logger
    logger = setup_logging(args.log_file)
    
    # åˆ›å»ºå¯¼å‡ºå™¨å¹¶è¿è¡Œ
    exporter = DataExporter(args.output_dir)
    
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output_dir}")
    
    exporter.run()


if __name__ == "__main__":
    main()
